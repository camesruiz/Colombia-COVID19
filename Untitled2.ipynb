{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0Z7MEaZZ3cuetjT5fp/4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camesruiz/Colombia-COVID19/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSKFG_DnIUE6"
      },
      "source": [
        "**CITIES4FOREST EXCHANGE SCRAPE**\n",
        "\n",
        "Code to get keywords from the articles present in the 'Exchenge' section of the Cities4Forests platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C08M4zwvjRyx"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAus6MNnoxjI"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsNOkxjNJJhL"
      },
      "source": [
        "List of links scraped from https://cities4forests.com/exchanges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIFAxwxTivvh"
      },
      "source": [
        "#Article title and links are pulled from the https://cities4forests.com/exchanges/ webpage\n",
        "html = requests.get('https://cities4forests.com/exchanges/')\n",
        "soup = BeautifulSoup(html.text,'html5lib')\n",
        "h2 = soup.find_all('div',{'class': \"c4f-content-news stori-page\"})\n",
        "\n",
        "title = []\n",
        "links = []\n",
        "keywords = []\n",
        "\n",
        "#For every scraped article, algorithm gets title and link, store them on a dict\n",
        "#and save them on a CSV file\n",
        "for link in h2:\n",
        "  mylink = BeautifulSoup(str(link),'html.parser')\n",
        "  getLink = mylink.find('a',href=True) #homepage\n",
        "  getTitle = mylink.find('h2') #homepage\n",
        "\n",
        "  if str(type(getLink)) == \"<class 'bs4.element.Tag'>\":\n",
        "\n",
        "    title.append(getTitle.get_text(strip=True))\n",
        "    links.append(str(getLink['href']))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRzwEdkKvIu5"
      },
      "source": [
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZhWsVSOJZyk"
      },
      "source": [
        "Functions to get text from the webpages and keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1AnCoRDi7_z"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def get_article_text(link):\n",
        "  html = requests.get(link)\n",
        "  soup = BeautifulSoup(html.text,'html5lib')\n",
        "  div = soup.find('div',{'class': \"entry-content\"})\n",
        "\n",
        "  mylink = BeautifulSoup(str(link),'html.parser')\n",
        "  getLink = mylink.find('p',href=False) #homepage\n",
        "\n",
        "  text = div.get_text()\n",
        "\n",
        "  text = text.replace('\\n', ' ')\n",
        "  return text\n",
        "  \n",
        "\n",
        "def get_keywords(text,number_of_keywords):\n",
        "    \n",
        "  tokens = [w for w in word_tokenize(text.lower()) if w.isalpha() and (w not in stop_words)] #text tokenize\n",
        "  token_lemma = [lemmatizer.lemmatize(token) for token in tokens] #lemmatization to normalize similar words\n",
        "  counter = Counter(token_lemma)\n",
        "  words = counter.most_common(number_of_keywords) #most common words\n",
        "\n",
        "  keyword_list = [word[0] for word in words]\n",
        "  return keyword_list\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_smmHUVjFYu",
        "outputId": "0e7ada24-b4b3-440c-8db7-6719a1d7f94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for link in links:\n",
        "  if 'https://cities4forests.com/wp-content/uploads/2019/05/C4F-PR-120918-1.pdf' not in link:\n",
        "    txt = get_article_text(link)\n",
        "    keywords.append(get_keywords(txt,10))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://cities4forests.com/exchange/community-climate-action-cop25/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://cities4forests.com/exchange/cities-from-across-the-world-are-tapping-nature-based-solutions-to-address-water-crises/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://cities4forests.com/exchange/buenos-aires-2019/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://cities4forests.com/exchange/oslo-2019/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7nsREOJu9C"
      },
      "source": [
        "Save dataframe to the cities4forests_exchange.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NJjHNxXlYPN",
        "outputId": "75639d2a-349b-4a4a-ecd6-f093a9b41c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "filename = \"cities4forests_exchange.csv\"\n",
        "print (f\"\\nSaved data to {filename}\")\n",
        "df = pd.DataFrame(list(zip(title,links,keywords)),\n",
        "                    columns=[\"TITLE\",\"LINKS\",\"KEYWORDS\"])\n",
        "df.to_csv(filename, index=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved data to cities4forests_exchange.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}